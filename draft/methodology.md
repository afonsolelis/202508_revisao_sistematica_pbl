# 2. Methodology

This systematic literature review was conducted following the established guidelines by Kitchenham [1] for performing systematic reviews in software engineering contexts. The review process was structured into three main phases: planning, conduct, and reporting, ensuring a rigorous and transparent approach to identifying, selecting, and analyzing relevant literature.

## 2.1 Research Questions

The review was guided by four primary research questions:

1. **RQ1**: What are the main methodological challenges in assessing learning in PBL contexts?
2. **RQ2**: What instruments and technologies are being used to overcome these challenges?
3. **RQ3**: How can technology support more objective and scalable assessment in PBL?
4. **RQ4**: What gaps persist in assessing processual and collaborative competencies?

## 2.2 Search Strategy

### 2.2.1 Database Selection
The Web of Science database was selected as the primary source for this review based on its comprehensive coverage of high-quality, peer-reviewed publications in education and technology journals, robust citation metrics, and alignment with systematic review standards.

### 2.2.2 Search Strings
A structured search strategy was developed using multiple search strings aligned with the research questions. The search strings combined terms related to PBL ("project-based learning", "project based learning", "PBL"), assessment ("assessment", "evaluation", "grading"), and specific aspects such as challenges, instruments, technologies, and collaborative competencies.

### 2.2.3 Time Frame and Languages
The search was limited to articles published between January 2015 and December 2025 to ensure contemporary relevance. The search included articles published in English, Portuguese, and Spanish to capture a broader range of research perspectives.

## 2.3 Study Selection Process

### 2.3.1 Inclusion Criteria
Articles were included if they:
1. Focused specifically on assessment methods in Project-Based Learning contexts
2. Addressed methodological challenges, instruments, or technologies for PBL assessment
3. Were set in formal educational environments (schools, universities, professional training)
4. Included empirical research with student participants
5. Were published between 2015 and 2025

### 2.3.2 Exclusion Criteria
Articles were excluded if they:
1. Focused on traditional lecture-based instruction or non-PBL contexts
2. Were purely theoretical/conceptual without empirical validation
3. Were conference abstracts or posters
4. Focused on industrial or corporate training without educational context
5. Were literature reviews or meta-analyses (to avoid circularity)

### 2.3.3 Selection Procedure
The study selection process followed a two-phase approach:
1. **Phase 1**: Title and abstract screening to identify potentially relevant articles
2. **Phase 2**: Full-text review of selected articles to apply inclusion/exclusion criteria

Two independent reviewers conducted the selection process, with discrepancies resolved through discussion.

## 2.4 Quality Assessment

The quality of included studies was assessed based on methodological rigor, including:
- Sample size justification
- Data collection procedures
- Analysis methods
- Reporting transparency

## 2.5 Data Extraction and Synthesis

Data extraction focused on study characteristics, PBL implementation details, assessment approaches, identified challenges, proposed solutions, and outcomes. Data synthesis employed thematic analysis to identify common patterns and themes, complemented by descriptive statistics to characterize the body of evidence.