# 1. Introduction

Project-Based Learning (PBL) has emerged as a prominent pedagogical approach in higher education, particularly in STEM disciplines, where students engage with complex, real-world problems through extended collaborative projects. While PBL offers significant benefits in terms of developing technical competencies and transversal skills, it presents unique challenges for educators tasked with assessing student learning effectively. The assessment of PBL contexts is inherently complex due to its processual nature, collaborative dynamics, and the need to evaluate both individual contributions and collective outcomes.

Instructors and supervisors face particular difficulties in PBL environments where students work in teams over extended periods (often 6-12 weeks) with rotating roles and evolving requirements. These challenges include evaluating individual contributions within collaborative teams, measuring transversal competencies throughout the learning process, providing continuous feedback during lengthy project timelines, and simultaneously monitoring code quality, team dynamics, and individual progress. Traditional assessment methods, which often focus on summative evaluation of final products, are inadequate for capturing the multifaceted nature of learning in PBL contexts.

Despite the proliferation of technological tools aimed at supporting PBL implementation, existing solutions typically operate in isolation, addressing specific aspects of the PBL experience rather than providing a holistic view of the educational process. This fragmented approach limits the ability of instructors to make informed pedagogical decisions based on comprehensive data about student performance and project dynamics.

This systematic review aims to map the current state of research on assessment challenges in PBL environments, with a particular focus on identifying methodological difficulties, instruments, and technologies that can support teachers and supervisors in conducting more effective, objective, and scalable assessments. The review also seeks to identify persistent gaps in the literature that could inform future research directions, particularly in the application of emerging technologies such as Digital Twins and software architecture principles to educational assessment.

The findings from this review contribute to the growing body of knowledge on PBL assessment by providing a comprehensive overview of current practices, highlighting critical gaps in research and practice, and identifying opportunities for technological innovation in assessment methodologies. The review is particularly relevant for educators in engineering and computer science disciplines seeking to implement more effective assessment strategies in complex PBL environments, as well as for researchers and developers working on educational technologies designed to support instructor evaluation processes.